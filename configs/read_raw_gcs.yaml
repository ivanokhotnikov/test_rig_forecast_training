name: Read raw data
description: Read raw data files from the GCS bucket, specified by `bucket_name`.
  Uploads the combined data frame to the interim data directory in the GCS bucket.
inputs:
- {name: data_bucket_name, type: String, description: GCS data bucket}
outputs:
- {name: interim_data, type: Dataset, description: Interim data}
- {name: all_features, type: Artifact, description: Raw features artifact}
implementation:
  container:
    image: python:3.10-slim
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'openpyxl' 'kfp==1.8.13' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def read_raw_data(
          data_bucket_name: str,
          interim_data: Output[Dataset],
          all_features: Output[Artifact],
      ) -> None:
          """Read raw data files from the GCS bucket, specified by `bucket_name`. Uploads the combined data frame to the interim data directory in the GCS bucket.

          Args:
              data_bucket_name (str): GCS data bucket
              interim_data (Output[Dataset]): Interim data
              all_features (Output[Artifact]): Raw features artifact
          """
          import gc
          import json
          import logging
          import os

          import pandas as pd

          logging.basicConfig(level=logging.INFO)
          final_df = pd.DataFrame()
          raw_data_path = os.path.join('gcs', data_bucket_name, 'raw')
          for file in os.listdir(raw_data_path):
              logging.info(f'Reading {file} from {raw_data_path}')
              try:
                  if file.endswith('.csv') and 'RAW' in file:
                      current_df = pd.read_csv(
                          os.path.join(raw_data_path, file),
                          header=0,
                          index_col=False,
                      )
                  elif (file.endswith('.xlsx')
                        or file.endswith('.xls')) and 'RAW' in file:
                      current_df = pd.read_excel(
                          os.path.join(raw_data_path, file),
                          header=0,
                          index_col=False,
                      )
                  logging.info(f'{file} was read!')
                  final_df = pd.concat((final_df, current_df), ignore_index=True)
                  del current_df
                  gc.collect()
              except:
                  logging.info(f'Can\'t read {file}!')
                  continue
          final_df.to_csv(
              interim_data.path + '.csv',
              index=False,
          )
          interim_data_path = os.path.join('gcs', data_bucket_name, 'interim')
          final_df.to_csv(
              os.path.join(interim_data_path, 'interim_data.csv'),
              index=False,
          )
          with open(all_features.path, 'w') as features_file:
              features_file.write(json.dumps(final_df.columns.to_list()))

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - read_raw_data
