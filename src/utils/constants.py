import google.cloud.aiplatform as aip
import google.cloud.storage as storage

PROJECT_ID = 'test-rig-349313'
REGION = 'europe-west2'
PROJECT_NUMBER = 42869708044
VERTEX_REGIONS = {'europe-west1', 'europe-west2', 'europe-west4'}

RAW_DATA_BUCKET_NAME = 'test_rig_raw_data'
RAW_DATA_BUCKET_URI = f'gs://{RAW_DATA_BUCKET_NAME}'
INTERIM_DATA_BUCKET_NAME = 'test_rig_interim_data'
INTERIM_DATA_BUCKET_URI = f'gs://{INTERIM_DATA_BUCKET_NAME}'
PROCESSED_DATA_BUCKET_NAME = 'test_rig_processed_data'
PROCESSED_DATA_BUCKET_URI = f'gs://{PROCESSED_DATA_BUCKET_NAME}'
PIPELINES_BUCKET_NAME = 'test_rig_pipelines'
PIPELINES_BUCKET_URI = f'gs://{PIPELINES_BUCKET_NAME}'
FEATURES_BUCKET_NAME = 'test_rig_features'
FEATURES_BUCKET_URI = f'gs://{FEATURES_BUCKET_NAME}'
MODELS_BUCKET_NAME = 'models_forecasting'
MODELS_BUCKET_URI = f'gs://{MODELS_BUCKET_NAME}'

STORAGE_CLIENT = storage.Client()
RAW_DATA_BUCKET = STORAGE_CLIENT.get_bucket(RAW_DATA_BUCKET_NAME)
INTERIM_DATA_BUCKET = STORAGE_CLIENT.get_bucket(INTERIM_DATA_BUCKET_NAME)
PROCESSED_DATA_BUCKET = STORAGE_CLIENT.get_bucket(PROCESSED_DATA_BUCKET_NAME)
MODELS_BUCKET = STORAGE_CLIENT.get_bucket(MODELS_BUCKET_NAME)
FEATURES_BUCKET = STORAGE_CLIENT.get_bucket(FEATURES_BUCKET_NAME)

TRAIN_GPU, TRAIN_NGPU = (aip.gapic.AcceleratorType.NVIDIA_TESLA_T4, 2)
TRAIN_CPU_PREFIX = 'tf-cpu.2-9'
TRAIN_GPU_PREFIX = 'tf-gpu.2-9'
TRAIN_CPU_IMAGE = f'{REGION.split("-")[0]}-docker.pkg.dev/vertex-ai/training/{TRAIN_CPU_PREFIX}:latest'
TRAIN_GPU_IMAGE = f'{REGION.split("-")[0]}-docker.pkg.dev/vertex-ai/training/{TRAIN_GPU_PREFIX}:latest'

MACHINE_TYPE = 'n1-standard'
VCPU = '4'
TRAIN_COMPUTE = MACHINE_TYPE + '-' + VCPU
MEMORY_LIMIT = '16G'
SLEEP_TIME = 1.05
